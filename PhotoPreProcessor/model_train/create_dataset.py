import kagglehub
import os
from dataset.real_fake_dataset import RealFakeDataset
from dataset.real_fake_folder_dataset import RealFakeFolderDataset
from datasets import load_dataset
from torchvision import datasets
import torch
from torch.utils.data import DataLoader, random_split, ConcatDataset

from dataset.ela_dataset import ELADataset  # ELADataset í´ë˜ìŠ¤ ì •ì˜í•œ íŒŒì¼ì—ì„œ import
from glob import glob
from random import sample
from sklearn.model_selection import train_test_split

# AI ìƒì„± ì‚¬ì§„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ë°ì´í„°
# ë°ì´í„°ì…‹ ì¶œì²˜ : https://www.kaggle.com/datasets/duyminhle/real-fake-image-full-dataset/data?select=1_fake
# path = kagglehub.dataset_download("duyminhle/real-fake-image-full-dataset")
# print("Path to dataset files:", path)
# Path to dataset files: C:\Users\cn120\.cache\kagglehub\datasets\duyminhle\real-fake-image-full-dataset\versions\1

# AI ìƒì„± ì‚¬ì§„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ë°ì´í„°
# ë°ì´í„°ì…‹ ì¶œì²˜ : https://www.kaggle.com/datasets/tristanzhang32/ai-generated-images-vs-real-images/data
# path = kagglehub.dataset_download("tristanzhang32/ai-generated-images-vs-real-images")
# print("Path to dataset files:", path)
# Path to dataset files: C:\Users\cn120\.cache\kagglehub\datasets\tristanzhang32\ai-generated-images-vs-real-images\versions\2

# ì´ ì™¸ì—ë„ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œë„ ë‹¤ìš´ë¡œë“œí–ˆìŒ.

# í•©ì„± ì‚¬ì§„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ë°ì´í„° 
# ë°ì´í„°ì…‹ ì¶œì²˜ : https://www.kaggle.com/datasets/divg07/casia-20-image-tampering-detection-dataset/data
path = kagglehub.dataset_download("divg07/casia-20-image-tampering-detection-dataset")
print("Path to dataset files:", path)
# Path to dataset files: C:\Users\cn120\.cache\kagglehub\datasets\divg07\casia-20-image-tampering-detection-dataset\versions\1

def train_real_fake_single_dataset(transform):
    # kagglehub ê²½ë¡œ ì˜ˆì‹œ
    folder_path = r"C:\Users\cn120\.cache\kagglehub\datasets\tristanzhang32\ai-generated-images-vs-real-images\versions\2"
    folder_dataset = RealFakeFolderDataset(folder_path, transform=transform)
    train_dir = os.path.join(folder_path, "train")
    test_dir = os.path.join(folder_path, "test")

    # PyTorch ImageFolderë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
    train_dataset = datasets.ImageFolder(train_dir, transform=transform)
    val_dataset = datasets.ImageFolder(test_dir, transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # âœ… í™•ì¸
    print(f"ë¡œì»¬ ì´ë¯¸ì§€ ìˆ˜: {len(folder_dataset)}")
    print(f"ì „ì²´ í•™ìŠµìš© ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}")
    print(f"ì „ì²´ ê²€ì¦ìš© ìƒ˜í”Œ ìˆ˜: {len(val_dataset)}")
    return train_loader, val_loader

def train_combined_dataset(transform): 
    folder_path = r"C:\Users\cn120\.cache\kagglehub\datasets\duyminhle\real-fake-image-full-dataset\versions\1"

    # ğŸ“¦ Dataset ìƒì„±
    folder_dataset = RealFakeFolderDataset(folder_path, transform=transform)
    hf_dataset_raw = load_dataset("date3k2/raw_real_fake_images")
    hf_dataset = RealFakeDataset(hf_dataset_raw["train"], transform=transform)

    # ğŸ”€ ë³‘í•© + 8:2 ë¹„ìœ¨ ë¶„ë¦¬
    full_combined_dataset = ConcatDataset([folder_dataset, hf_dataset])
    train_size = int(0.8 * len(full_combined_dataset))
    val_size = len(full_combined_dataset) - train_size
    generator = torch.Generator().manual_seed(42)

    train_dataset, val_dataset = random_split(full_combined_dataset, [train_size, val_size], generator=generator)

    # ğŸ“¤ DataLoader
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # âœ… í™•ì¸
    print(f"ë¡œì»¬ ì´ë¯¸ì§€ ìˆ˜: {len(folder_dataset)}")
    print(f"HuggingFace ì´ë¯¸ì§€ ìˆ˜: {len(hf_dataset)}")
    print(f"ì „ì²´ í•™ìŠµìš© ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}")
    print(f"ì „ì²´ ê²€ì¦ìš© ìƒ˜í”Œ ìˆ˜: {len(val_dataset)}")
    return train_loader, val_loader

def train_tampering_single_dataset(transform, batch_size=32, num_workers=1):
    # ë°ì´í„°ì…‹ ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)
    base_path = r"C:\Users\cn120\.cache\kagglehub\datasets\divg07\casia-20-image-tampering-detection-dataset\versions\1\CASIA2"
    au_dir = os.path.join(base_path, "Au")
    tp_dir = os.path.join(base_path, "Tp")

    # âœ… í™•ì¥ìë³„ ìˆ˜ì§‘
    def collect_images(folder):
        return glob(os.path.join(folder, "*.jpg")) + \
               glob(os.path.join(folder, "*.png")) + \
               glob(os.path.join(folder, "*.tif"))

    real_paths = collect_images(au_dir)
    fake_paths = collect_images(tp_dir)

    # âœ… ì–¸ë”ìƒ˜í”Œë§: real ì´ë¯¸ì§€ë¥¼ fake ìˆ˜ì— ë§ì¶¤
    selected_real = sample(real_paths, len(fake_paths))

    all_paths = selected_real + fake_paths
    all_labels = [1] * len(selected_real) + [0] * len(fake_paths)

    # í•™ìŠµ/ê²€ì¦ ë¶„í• 
    X_train, X_val, y_train, y_val = train_test_split(all_paths, all_labels, test_size=0.2, random_state=42)

    # ì»¤ìŠ¤í…€ Dataset êµ¬ì„±
    train_dataset = ELADataset(X_train, y_train, transform=transform)
    val_dataset = ELADataset(X_val, y_val, transform=transform)

    # DataLoader êµ¬ì„±
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    print(f"ë¡œì»¬ ì´ë¯¸ì§€ ìˆ˜: {len(all_paths)}")
    print(f"ì „ì²´ í•™ìŠµìš© ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}")
    print(f"ì „ì²´ ê²€ì¦ìš© ìƒ˜í”Œ ìˆ˜: {len(val_dataset)}")
    return train_loader, val_loader